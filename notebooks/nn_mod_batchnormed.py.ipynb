{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [15, 10]\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2584\r\n",
      "drwxr-xr-x   6 dsp  staff      204 Sep 30 17:04 \u001b[34m.\u001b[m\u001b[m\r\n",
      "drwxr-xr-x  11 dsp  staff      374 Jul  1 16:27 \u001b[34m..\u001b[m\u001b[m\r\n",
      "-rw-r--r--@  1 dsp  staff     6148 Sep 30 17:04 .DS_Store\r\n",
      "-rw-r--r--@  1 dsp  staff    64799 Sep 30 16:49 Multistock.csv\r\n",
      "-rw-r--r--@  1 dsp  staff    69786 Sep 30 17:32 buyStats.csv\r\n",
      "-rw-r--r--@  1 dsp  staff  1175009 Sep 30 00:05 sp1950.csv\r\n"
     ]
    }
   ],
   "source": [
    "!../scripts/copy_data.sh\n",
    "!ls -la ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read(filepath, pred=False):\n",
    "    dat = pd.read_csv(filepath)\n",
    "    if not pred:\n",
    "        dat['buyDate'] = pd.to_datetime(dat['buyDate'])\n",
    "    return dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dat = read(DATA_PATH + 'buyStats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_commas(value):\n",
    "    if type(value) == str:\n",
    "        return float(value.replace(',', ''))\n",
    "    else:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat['freeCashFlow_'] = dat['freeCashFlow_'].apply(lambda x: remove_commas(x))\n",
    "dat['mCap_'] = dat['mCap_'].apply(lambda x: remove_commas(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aerospaceAndDefense, airlines, autoComponents, automobiles, banks, beverages, biotechnology, capitalMarkets, chemicals, communicationEquipment, constructionAndEngineering, constructionMaterials, diversifiedConsumerServices, diversifiedTelecommunicationServices, electricUtilities, electronicEquipmentInstrumentsAndComponents, energyEquipmentAndServices, equityRealEstateInvestmentTrusts, foodAndStaplesRetailing, foodProducts, gasUtilities, healthCareEquipmentAndSupplies, healthCareProvidersAndServices, healthCareTechnology, hotelsRestaurantsAndLeisure, householdDurables, independentPowerAndRenewableElectricityProducers, industrialConglomerates, insurance, internetAndDirectMarketingRetail, internetSoftwareAndServices, itServices, leisureProducts, lifeSciencesToolsAndServices, machinery, media, metalsAndMining, mortgageRealEstateInvestmentTrusts, nan, oilGasAndConsumableFuels, paperAndForestProducts, personalProducts, pharmaceuticals, professionalServices, roadAndRail, semiconductorsAndSemiconductorEquipment, software, specialtyRetail, technologyHardwareStorageAndPeripherals, textilesApparelAndLuxuryGoods, transportationInfrastructure, wirelessTelecommunicationServices, \n",
      "\n",
      "largeCap, midCap, nan, \n",
      "\n",
      "basicMaterials, capitalGoods, consumerCyclical, consumerNonCyclical, energy, financial, healthcare, nan, services, technology, transportation, "
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat['industry'] = dat['industry'].apply(lambda x: str(x))\n",
    "dat['size']     = dat['size'].apply(lambda x: str(x))\n",
    "dat['sector']   = dat['sector'].apply(lambda x: str(x))\n",
    "industries = sorted(np.unique(dat['industry']))\n",
    "sizes      = sorted(np.unique(dat['size']))\n",
    "sectors    = sorted(np.unique(dat['sector']))\n",
    "[print(ind, end=', ') for ind in industries]\n",
    "print('\\n')\n",
    "[print(size, end=', ') for size in sizes]\n",
    "print('\\n')\n",
    "[print(sec, end=', ') for sec in sectors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot(df):\n",
    "    X = df.copy()\n",
    "    X[industries] = pd.get_dummies(X['industry'])\n",
    "    X[sizes]      = pd.get_dummies(X['size'])\n",
    "    X[sectors]    = pd.get_dummies(X['sector'])\n",
    "    X[['mfHold', 'mfNone', 'mfNow', 'mfStart']] = pd.get_dummies(X['MF'])\n",
    "    X = X.drop(['industry', 'size', 'sector', 'MF'], axis=1)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat = one_hot(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def median_fill(df):\n",
    "    X = df.copy()\n",
    "\n",
    "    for col in list(X):\n",
    "        try:\n",
    "            X[col][np.isnan(X[col])] = np.nanmedian(X[col])\n",
    "        except:\n",
    "            print('Could not fill column', col)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not fill column stock\n",
      "Could not fill column buyDate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/lib/python3.6/site-packages/numpy/lib/function_base.py:3858: RuntimeWarning: All-NaN slice encountered\n",
      "  r = func(a, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "dat = median_fill(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2017-09-29 00:00:00')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today = datetime.datetime.now()\n",
    "if today.weekday() == 5:\n",
    "    today = today - datetime.timedelta(days=1)\n",
    "if today.weekday() == 6:\n",
    "    today = today - datetime.timedelta(days=2)\n",
    "today = str(today).split(' ')[0]\n",
    "today = pd.to_datetime(today)\n",
    "today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_dat = dat.loc[dat['buyDate'] > today, :]\n",
    "dat     = dat.loc[dat['buyDate'] <= today, :]\n",
    "stocks = new_dat['stock']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_missing(dfs, y_col):\n",
    "    X = dfs[0].copy()\n",
    "    # cols\n",
    "    drop_cols = [col for col in list(X) if type(col[0]) == np.float and col.isnan().all()]\n",
    "    X = X.drop(drop_cols, axis=1)\n",
    "    X2 = dfs[1].drop(drop_cols, axis=1)\n",
    "    return X.loc[np.isnan(dat[y_col]) == False, :], X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat, new_dat = drop_missing([dat, new_dat], 'd30Gains')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_xy(df, y_col, first_X):\n",
    "    y = df[y_col]\n",
    "    start_col = list(df).index(first_X)\n",
    "    X = df.iloc[:, start_col:]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y         = split_xy(dat,     'd30Gains', 'MFRisk')\n",
    "X_new, y_new = split_xy(new_dat, 'd30Gains', 'MFRisk')\n",
    "[print('Mismatch:', x, xn) for (x, xn) in zip(list(X), list(X_new)) \n",
    " if x != xn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size:   149\n",
      "Validation size: 32\n",
      "Test       size: 32\n"
     ]
    }
   ],
   "source": [
    "n = X.shape[0]\n",
    "TRAIN = 0.7\n",
    "VALIDATE = 0.15\n",
    "TEST = 0.15\n",
    "print(\n",
    "    'Training size:   %.0f\\nValidation size: %.0f\\nTest       size: %.0f'\n",
    "    %(TRAIN * n, VALIDATE * n, TEST * n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train, Not Train\n",
    "X_train, X_vt, y_train, y_vt = train_test_split(\n",
    "    X, y, test_size=VALIDATE + TEST)\n",
    "\n",
    "# Validate Test\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(\n",
    "    X_vt, y_vt, test_size=(TEST / (TEST + VALIDATE)))\n",
    "\n",
    "# Reindex\n",
    "X_train.index = range(len(y_train))\n",
    "y_train.index = range(len(y_train))\n",
    "\n",
    "X_valid.index = range(len(y_valid))\n",
    "y_valid.index = range(len(y_valid))\n",
    "\n",
    "X_test.index = range(len(y_test))\n",
    "y_test.index = range(len(y_test))\n",
    "y_test = y_test.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:    (149, 122)\n",
      "validate: (32, 122)\n",
      "test:     (32, 122)\n",
      "new:      (3, 122)\n"
     ]
    }
   ],
   "source": [
    "print('train:   ', X_train.shape)\n",
    "print('validate:', X_valid.shape)\n",
    "print('test:    ', X_test.shape)\n",
    "print('new:     ', X_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# WHILE DATA SET IS SMALL, restrict values in new data to the range seen \n",
    "# in training data\n",
    "if X_test.shape[0] < 100:\n",
    "    for col in list(X_train):\n",
    "        if col not in ['spVal', 'days']:\n",
    "            mn, mx = np.min(X_train[col]), np.max(X_train[col])\n",
    "            X_new[col][X_new[col] < mn] = mn\n",
    "            X_new[col][X_new[col] > mx] = mx\n",
    "else: \n",
    "    print('Data large enough.  Remove this cell.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remove_empties = []\n",
    "\n",
    "for col in list(X_train):\n",
    "    try:\n",
    "        if np.isnan(X_train[col]).any():\n",
    "            remove_empties.append(col)\n",
    "            print('Removing ', col)\n",
    "    except:\n",
    "        print('\\tCould not check', col)\n",
    "        \n",
    "X_train = X_train.drop(remove_empties, axis=1)\n",
    "X_valid = X_valid.drop(remove_empties, axis=1)\n",
    "X_test  = X_test.drop(remove_empties, axis=1)\n",
    "X_new   = X_new.drop(remove_empties, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_new  = scaler.transform(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!mkdir stock_model_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_norm(x, n_out, phase_train, layer_type):\n",
    "    beta_init  = tf.constant_initializer(value=0.0, dtype=tf.float32)\n",
    "    gamma_init = tf.constant_initializer(value=1.0, dtype=tf.float32)\n",
    "    beta  = tf.get_variable('beta',  [n_out], initializer=beta_init)\n",
    "    gamma = tf.get_variable('gamma', [n_out], initializer=gamma_init)\n",
    "    axes = [0, 1, 2] if layer_type == 'conv' else [0]\n",
    "    batch_mean, batch_var = tf.nn.moments(x, axes, name='moments')\n",
    "    ema = tf.train.ExponentialMovingAverage(decay=0.9)\n",
    "    ema_apply_op = ema.apply([batch_mean, batch_var])\n",
    "    \n",
    "    def  mean_var_with_update():\n",
    "        with tf.control_dependencies([ema_apply_op]):\n",
    "            return tf.identity(batch_mean), tf.identity(batch_var)\n",
    "    \n",
    "    ema_mean, ema_var = ema.average(batch_mean), ema.average(batch_var)\n",
    "    mean, var = control_flow_ops.cond(\n",
    "        phase_train, mean_var_with_update, lambda: (ema_mean, ema_var))\n",
    "    \n",
    "    if layer_type != 'conv':\n",
    "        x = tf.reshape(x, [-1, 1, 1, n_out])\n",
    "    normed = tf.nn.batch_norm_with_global_normalization(\n",
    "        x, mean, var, beta, gamma, 1e-3, True)\n",
    "    \n",
    "    if layer_type != 'conv':\n",
    "        normed = tf.reshape(normed, [-1, n_out])\n",
    "    return normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def layer_batch_norm(x, n_out, phase_train):\n",
    "    return batch_norm(x, n_out, phase_train, 'fully_connected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a fully-connected layer\n",
    "def layer(input, weight_shape, bias_shape, phase_train):\n",
    "    weight_init = tf.random_normal_initializer(\n",
    "        stddev=(2. / weight_shape[0]) ** 0.5)\n",
    "    bias_init = tf.constant_initializer(value=0)\n",
    "    W = tf.get_variable('W', weight_shape, initializer=weight_init)\n",
    "    b = tf.get_variable('b', bias_shape, initializer=bias_init)\n",
    "    logits = tf.matmul(input, W) + b\n",
    "    return tf.nn.relu(layer_batch_norm(\n",
    "        logits, weight_shape[1], phase_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make with 2 fc layers, then update to generalize\n",
    "def inference(x, keep_prob, phase_train, n_neurons):\n",
    "    inputs = x\n",
    "    for i in range(len(n_neurons) - 1):\n",
    "        with tf.variable_scope('fc' + str(i + 1)):\n",
    "            inputs = layer(inputs, \n",
    "                           [n_neurons[i], n_neurons[i + 1]],\n",
    "                           n_neurons[i + 1],\n",
    "                           phase_train)\n",
    "            inputs = tf.nn.dropout(inputs, keep_prob)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loss(output, y):\n",
    "    #cost = tf.reduce_sum(tf.pow(output - y, 2)) # SSE\n",
    "    cost = tf.sqrt(\n",
    "        tf.reduce_mean(tf.square(tf.subtract(y, output)))) # RMSE\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training(cost, global_step):\n",
    "    #tf.summary.scalar('cost', cost)\n",
    "    eta0 = ETA\n",
    "    eta = tf.train.exponential_decay(\n",
    "        eta0, global_step, DECAY_STEPS, DECAY_RATE, name='eta')\n",
    "    optimizer = tf.train.AdamOptimizer(eta)\n",
    "    train_op = optimizer.minimize(cost, global_step=global_step)\n",
    "    return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ops.reset_default_graph()\n",
    "g = tf.get_default_graph()\n",
    "[op.name for op in g.get_operations()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training(cost, global_step):\n",
    "    #tf.summary.scalar('cost', cost)\n",
    "    optimizer = tf.train.AdamOptimizer(ETA)\n",
    "    train_op = optimizer.minimize(cost, global_step=global_step)\n",
    "    return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run only before first model is executed\n",
    "best_error_so_far = np.Inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N, D = X_train.shape\n",
    "\n",
    "# Hyperparmeters to tune\n",
    "DROPOUT_RATE = 0.0\n",
    "n_neurons = [D, D, D, D, D, 1]\n",
    "\n",
    "# Programmed Learning with Decay\n",
    "ETA = 0.005 # Learning rate\n",
    "DECAY_STEPS = 100  # eta updates after this many epochs\n",
    "DECAY_RATE = 0.99  # factor to change eta by\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10000\n",
    "\n",
    "DISPLAY_STEP = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 Cost: 0.44648150\tValidation cost: 7.14571285\n",
      "Epoch: 0501 Cost: 0.32988662\tValidation cost: 0.64638782\n",
      "Epoch: 1001 Cost: 0.32988667\tValidation cost: 0.64638847\n",
      "Epoch: 1501 Cost: 0.32988647\tValidation cost: 0.64618456\n",
      "Epoch: 2001 Cost: 0.32988653\tValidation cost: 0.64437330\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-242-869dd56b5cb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m                     saver.save(sess, \n\u001b[1;32m     53\u001b[0m                                \u001b[0;34m'stock_model_logs/model-checkpoint'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                                global_step=global_step)\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Optimization complete...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             test_rmse = sess.run(cost, \n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state)\u001b[0m\n\u001b[1;32m   1384\u001b[0m           checkpoint_file, meta_graph_suffix=meta_graph_suffix)\n\u001b[1;32m   1385\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1386\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_meta_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_graph_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_empty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mexport_meta_graph\u001b[0;34m(self, filename, collection_list, as_text, export_scope, clear_devices)\u001b[0m\n\u001b[1;32m   1417\u001b[0m         \u001b[0mas_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1418\u001b[0m         \u001b[0mexport_scope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexport_scope\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1419\u001b[0;31m         clear_devices=clear_devices)\n\u001b[0m\u001b[1;32m   1420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1421\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mexport_meta_graph\u001b[0;34m(filename, meta_info_def, graph_def, saver_def, collection_list, as_text, graph, export_scope, clear_devices, **kwargs)\u001b[0m\n\u001b[1;32m   1639\u001b[0m       \u001b[0mexport_scope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexport_scope\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1640\u001b[0m       \u001b[0mclear_devices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclear_devices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1641\u001b[0;31m       **kwargs)\n\u001b[0m\u001b[1;32m   1642\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/meta_graph.py\u001b[0m in \u001b[0;36mexport_scoped_meta_graph\u001b[0;34m(filename, graph_def, graph, export_scope, as_text, unbound_inputs_col_name, clear_devices, **kwargs)\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m         as_text=as_text)\n\u001b[0m\u001b[1;32m    648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mscoped_meta_graph_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/graph_io.py\u001b[0m in \u001b[0;36mwrite_graph\u001b[0;34m(graph_or_graph_def, logdir, name, as_text)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mfile_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matomic_write_string_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mfile_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matomic_write_string_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/google/protobuf/internal/python_message.py\u001b[0m in \u001b[0;36mSerializeToString\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1033\u001b[0m           'Message %s is missing required fields: %s' % (\n\u001b[1;32m   1034\u001b[0m           self.DESCRIPTOR.full_name, ','.join(self.FindInitializationErrors())))\n\u001b[0;32m-> 1035\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializePartialToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1036\u001b[0m   \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSerializeToString\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/google/protobuf/internal/python_message.py\u001b[0m in \u001b[0;36mSerializePartialToString\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1042\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mSerializePartialToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_InternalSerialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m   \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializePartialToString\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSerializePartialToString\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/google/protobuf/internal/python_message.py\u001b[0m in \u001b[0;36mInternalSerialize\u001b[0;34m(self, write_bytes)\u001b[0m\n\u001b[1;32m   1048\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mInternalSerialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mListFields\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m       \u001b[0mfield_descriptor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtag_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_bytes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unknown_fields\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m       \u001b[0mwrite_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/google/protobuf/internal/encoder.py\u001b[0m in \u001b[0;36mEncodeField\u001b[0;34m(write, value)\u001b[0m\n\u001b[1;32m    760\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mEncodeField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m       \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m       \u001b[0mlocal_EncodeVarint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_InternalSerialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mEncodeField\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/google/protobuf/internal/python_message.py\u001b[0m in \u001b[0;36mByteSize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1010\u001b[0m     \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mListFields\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1012\u001b[0;31m       \u001b[0msize\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtag_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_bytes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unknown_fields\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/google/protobuf/internal/encoder.py\u001b[0m in \u001b[0;36mRepeatedFieldSize\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    300\u001b[0m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtag_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlocal_VarintSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/google/protobuf/internal/python_message.py\u001b[0m in \u001b[0;36mByteSize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1010\u001b[0m     \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mListFields\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1012\u001b[0;31m       \u001b[0msize\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtag_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_bytes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unknown_fields\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/google/protobuf/internal/encoder.py\u001b[0m in \u001b[0;36mFieldSize\u001b[0;34m(map_value)\u001b[0m\n\u001b[1;32m    358\u001b[0m       \u001b[0;31m# duplication.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m       \u001b[0mentry_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessage_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m       \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmessage_sizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/google/protobuf/internal/encoder.py\u001b[0m in \u001b[0;36mFieldSize\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    306\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mFieldSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m       \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtag_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlocal_VarintSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mFieldSize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/google/protobuf/internal/python_message.py\u001b[0m in \u001b[0;36mByteSize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1010\u001b[0m     \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mListFields\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1012\u001b[0;31m       \u001b[0msize\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtag_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_bytes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unknown_fields\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/google/protobuf/internal/encoder.py\u001b[0m in \u001b[0;36mFieldSize\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    306\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mFieldSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m       \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtag_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlocal_VarintSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mFieldSize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/google/protobuf/internal/python_message.py\u001b[0m in \u001b[0;36mByteSize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1010\u001b[0m     \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mListFields\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1012\u001b[0;31m       \u001b[0msize\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtag_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_bytes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unknown_fields\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/google/protobuf/internal/encoder.py\u001b[0m in \u001b[0;36mFieldSize\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    306\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mFieldSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m       \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtag_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlocal_VarintSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mFieldSize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/google/protobuf/internal/python_message.py\u001b[0m in \u001b[0;36mByteSize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1010\u001b[0m     \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mListFields\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1012\u001b[0;31m       \u001b[0msize\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtag_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_bytes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unknown_fields\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/google/protobuf/internal/encoder.py\u001b[0m in \u001b[0;36mRepeatedFieldSize\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mRepeatedFieldSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtag_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlocal_VarintSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/google/protobuf/internal/containers.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m   \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m     \u001b[0;34m\"\"\"Retrieves item by the specified key.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_err = []\n",
    "valid_err = []\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    with tf.Graph().as_default():\n",
    "        with tf.variable_scope('stock_mod'):\n",
    "            # Init\n",
    "            X = tf.placeholder(tf.float32, shape=[None, D], name='X')\n",
    "            y = tf.placeholder(tf.float32, shape=None, name='y')\n",
    "            keep_prob = tf.placeholder(tf.float32)\n",
    "            phase_train = tf.placeholder(tf.bool) # T=train, F=Valid/Test\n",
    "            output = inference(X, keep_prob, phase_train, n_neurons)\n",
    "            cost = loss(output, y)\n",
    "            global_step = tf.Variable(\n",
    "                0, name='global_step', trainable=False)\n",
    "            train_op = training(cost, global_step)\n",
    "            saver = tf.train.Saver()\n",
    "            sess = tf.Session()\n",
    "            init_op = tf.global_variables_initializer()\n",
    "            sess.run(init_op)\n",
    "            tf.train.start_queue_runners(sess=sess)\n",
    "            \n",
    "            # Train\n",
    "            for epoch in range(EPOCHS):\n",
    "                avg_rmse = 0.\n",
    "                idxs = np.random.permutation(range(N))\n",
    "                n_batches = len(idxs) // BATCH_SIZE\n",
    "                \n",
    "                for batch in range(n_batches):\n",
    "                    _, new_cost = sess.run(\n",
    "                        [train_op, cost],\n",
    "                        feed_dict={X: X_train[idxs, :],\n",
    "                                   y: y_train[idxs],\n",
    "                                   keep_prob: 1 - DROPOUT_RATE,\n",
    "                                   phase_train: True})\n",
    "                avg_rmse += new_cost / n_batches\n",
    "                train_err.append(avg_rmse)\n",
    "\n",
    "                validate_rmse = sess.run(\n",
    "                    cost,\n",
    "                    feed_dict={X: X_valid,\n",
    "                               y: y_valid,\n",
    "                               keep_prob: 1.,\n",
    "                               phase_train: False})\n",
    "                valid_err.append(validate_rmse)\n",
    "\n",
    "                # Display output per display step\n",
    "                if epoch % DISPLAY_STEP == 0:\n",
    "                    print('Epoch: %04d Cost: %.8f\\tValidation cost: %.8f' \n",
    "                          %(epoch + 1, avg_rmse, validate_rmse))\n",
    "\n",
    "                    saver.save(sess, \n",
    "                               'stock_model_logs/model-checkpoint', \n",
    "                               global_step=global_step)\n",
    "            print('Optimization complete...')\n",
    "            test_rmse = sess.run(cost, \n",
    "                                feed_dict={X: X_test,\n",
    "                                           y: y_test,\n",
    "                                           keep_prob: 1.,\n",
    "                                           phase_train: False})\n",
    "            print('Test RMSE: %.8f\\n\\n' %test_rmse)\n",
    "            \n",
    "            new_preds = sess.run(output, \n",
    "                                 feed_dict={X: X_new,\n",
    "                                            keep_prob: 1., \n",
    "                                            phase_train: False})\n",
    "            final_out = []\n",
    "            for (stock, pred) in zip(\n",
    "                    stocks, new_preds.reshape(new_preds.shape[0])):\n",
    "                final_out.append([stock, pred])\n",
    "    \n",
    "            out = pd.DataFrame(columns=['Stock', 'Prediction'], \n",
    "                               data=final_out)\n",
    "            out['LowerBound'] = out['Prediction'] - 2 * test_rmse\n",
    "            out['UpperBound'] = out['Prediction'] + 2 * test_rmse\n",
    "            out = out.sort_values('Prediction', ascending=False)\n",
    "            print(out.head(len(stocks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(train_err, 'k-', label='train');\n",
    "plt.plot(valid_err, 'r-', label='validate');\n",
    "plt.legend(loc='best');\n",
    "plt.xlabel('Epochs');\n",
    "plt.ylabel('RMSE');\n",
    "plt.yscale('log')\n",
    "#plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "appx_validation_error = np.mean(valid_err[-100:])\n",
    "print('Previous Best:', best_error_so_far)\n",
    "print('This run:     ', appx_validation_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if appx_validation_error < best_error_so_far:\n",
    "    best_error_so_far = appx_validation_error\n",
    "    print('New Best Model Found!\\nHyperparameters:\\n' + ('-' * 70))\n",
    "    hyperparams = {\n",
    "        'best_error_so_far': appx_validation_error,\n",
    "        'best_dropout': DROPOUT_RATE,\n",
    "        'best_architecture': n_neurons,\n",
    "        'best_eta': ETA,\n",
    "        'best_decay_steps': DECAY_STEPS,\n",
    "        'best_decay_rate': DECAY_RATE}\n",
    "for k, v in hyperparams.items():\n",
    "    print('%17s: %s' %(k, str(v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
